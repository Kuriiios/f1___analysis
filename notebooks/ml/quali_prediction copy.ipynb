{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07c877fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kurios/Documents/f1_analysis/f1_analysis_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import math\n",
    "import re\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import root_mean_squared_error as rmse\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from lightautoml.automl.presets.tabular_presets import TabularAutoML, TabularUtilizedAutoML\n",
    "from lightautoml.automl.presets.text_presets import TabularNLPAutoML\n",
    "from lightautoml.tasks import Task\n",
    "from lightautoml.report.report_deco import ReportDeco, ReportDecoUtilized\n",
    "from lightautoml.addons.tabular_interpretation import SSWARM\n",
    "import torch\n",
    "\n",
    "matplotlib.rcParams['font.size'] = 14\n",
    "matplotlib.rcParams['figure.figsize'] = (10, 6)\n",
    "matplotlib.rcParams['figure.facecolor'] = \"#949494\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "095d5f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_THREADS = 16\n",
    "N_FOLDS = 30\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "TIMEOUT = 3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd5cef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(ModelClass, **params):\n",
    "    model = ModelClass(**params).fit(X_train, Y_train)\n",
    "    train_rmse = rmse(model.predict(X_train), Y_train)\n",
    "    val_rmse = rmse(model.predict(X_val), Y_val)\n",
    "    return train_rmse, val_rmse\n",
    "\n",
    "def test_param_and_plot(ModelClass, param_name, param_values, **other_params):\n",
    "    train_errors, val_errors = [], [] \n",
    "    for value in param_values:\n",
    "        params = dict(other_params)\n",
    "        params[param_name] = value\n",
    "        train_rmse, val_rmse = test_params(ModelClass, **params)\n",
    "        train_errors.append(train_rmse)\n",
    "        val_errors.append(val_rmse)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.title('Overfitting curve: ' + param_name)\n",
    "    plt.plot(param_values, train_errors, 'b-o')\n",
    "    plt.plot(param_values, val_errors, 'r-o')\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel('RMSE')\n",
    "    plt.legend(['Training', 'Validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804a27e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2019 = pd.read_csv('practice_data_2019.csv')\n",
    "df_2020 = pd.read_csv('practice_data_2020.csv')\n",
    "df_2021 = pd.read_csv('practice_data_2021.csv')\n",
    "df_2022 = pd.read_csv('practice_data_2022.csv')\n",
    "df_2023 = pd.read_csv('practice_data_2023.csv')\n",
    "df_2024 = pd.read_csv('practice_data_2024.csv')\n",
    "\n",
    "train = pd.concat([df_2019, df_2020, df_2021, df_2022, df_2023])\n",
    "train_df = train.drop('Unnamed: 0', axis=1)\n",
    "val_df = df_2024.drop('Unnamed: 0', axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5601eebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.loc[:,'fastest_laptime']= pd.to_timedelta(train_df['fastest_laptime']).dt.total_seconds()\n",
    "train_df.loc[:,'avg_quick_laptime']= pd.to_timedelta(train_df['avg_quick_laptime']).dt.total_seconds()\n",
    "train_df.loc[:,'q1']= pd.to_timedelta(train_df['q1']).dt.total_seconds()\n",
    "train_df.loc[:,'q2']= pd.to_timedelta(train_df['q2']).dt.total_seconds()\n",
    "train_df.loc[:,'q3']= pd.to_timedelta(train_df['q3']).dt.total_seconds()\n",
    "\n",
    "val_df.loc[:,'fastest_laptime']= pd.to_timedelta(val_df['fastest_laptime']).dt.total_seconds()\n",
    "val_df.loc[:,'avg_quick_laptime']= pd.to_timedelta(val_df['avg_quick_laptime']).dt.total_seconds()\n",
    "val_df.loc[:,'q1']= pd.to_timedelta(val_df['q1']).dt.total_seconds()\n",
    "val_df.loc[:,'q2']= pd.to_timedelta(val_df['q2']).dt.total_seconds()\n",
    "val_df.loc[:,'q3']= pd.to_timedelta(val_df['q3']).dt.total_seconds()\n",
    "\n",
    "train_df['fastest_laptime'] = train_df['fastest_laptime'].astype(float)\n",
    "train_df['avg_quick_laptime'] = train_df['avg_quick_laptime'].astype(float)\n",
    "train_df['q1'] = train_df['q1'].astype(float)\n",
    "train_df['q2'] = train_df['q2'].astype(float)\n",
    "train_df['q3'] = train_df['q3'].astype(float)\n",
    "\n",
    "val_df['fastest_laptime'] = val_df['fastest_laptime'].astype(float)\n",
    "val_df['avg_quick_laptime'] = val_df['avg_quick_laptime'].astype(float)\n",
    "val_df['q1'] = val_df['q1'].astype(float)\n",
    "val_df['q2'] = val_df['q2'].astype(float)\n",
    "val_df['q3'] = val_df['q3'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9348c27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_COLS = ['Stint', 'Compound', 'LapCount', 'FirstLap', 'LastLap',\n",
    "       'race_number', 'fastest_laptime', 'number_quick_laptime',\n",
    "       'avg_quick_laptime', 'fp_session', 'SpeedTotal', 'high_engine_mode',\n",
    "       'low_engine_mode', 'quali_sim', 'race_sim']\n",
    "\n",
    "TARGET_NAME = 'q1'\n",
    "\n",
    "X_train = train_df[INPUT_COLS].copy()\n",
    "Y_train = train_df[TARGET_NAME].copy()\n",
    "\n",
    "X_val = val_df[INPUT_COLS].copy()\n",
    "Y_val = val_df[TARGET_NAME].copy()\n",
    "\n",
    "numeric_cols = X_train.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_cols = X_train.select_dtypes('object').columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9306de1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51900/1271075872.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df['q1'] = Y_train\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy='mean').fit(X_train[numeric_cols])\n",
    "\n",
    "X_train[numeric_cols] = imputer.transform(X_train[numeric_cols])\n",
    "Y_train = pd.DataFrame(Y_train)\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=120).fit(Y_train)\n",
    "\n",
    "Y_train = imputer.transform(Y_train)\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_train[numeric_cols])\n",
    "\n",
    "X_train[numeric_cols] = scaler.transform(X_train[numeric_cols])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').fit(X_train[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "X_train[encoded_cols] = encoder.transform(X_train[categorical_cols])\n",
    "\n",
    "train_df = X_train[numeric_cols + encoded_cols]\n",
    "\n",
    "train_df['q1'] = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d37f2b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='mean').fit(X_val[numeric_cols])\n",
    "\n",
    "X_val[numeric_cols] = imputer.transform(X_val[numeric_cols])\n",
    "Y_val = pd.DataFrame(Y_val)\n",
    "\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=120).fit(Y_val)\n",
    "\n",
    "Y_val = imputer.transform(Y_val)\n",
    "\n",
    "scaler = MinMaxScaler().fit(X_val[numeric_cols])\n",
    "\n",
    "X_val[numeric_cols] = scaler.transform(X_val[numeric_cols])\n",
    "\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore').fit(X_val[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "X_val[encoded_cols] = encoder.transform(X_val[categorical_cols])\n",
    "\n",
    "val_df = X_val[numeric_cols + encoded_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad2d4a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Task('reg', loss='rmsle', metric='rmsle')\n",
    "\n",
    "roles = {\n",
    "    'target': TARGET_NAME,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cd1bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "automl = TabularAutoML(task = task,\n",
    "                        timeout = TIMEOUT,\n",
    "                        cpu_limit = N_THREADS,\n",
    "                        reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE})\n",
    "train_preds = automl.fit_predict(train_df, roles = roles, verbose = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a81a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preds = automl.predict(X_train)\n",
    "train_preds = train_preds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7cc18e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4466488941518774"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(train_preds, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256dd5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_preds = automl.predict(X_val)\n",
    "val_preds = val_preds.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e346c346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.297406584536727"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse(val_preds, Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95602b16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "f1_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
